{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of toxic comment - 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "N64VMXyqoY_O"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, Input\n",
        "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "max_features = 20000\n",
        "maxlen = 100 \n",
        "\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/jigsaw-toxic-comment-classification-challenge/test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo_1q4Hlt4LQ"
      },
      "source": [
        "list_sentences_train = train[\"comment_text\"].fillna(\"CVxTz\").values\n",
        "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "y = train[list_classes].values\n",
        "list_sentences_test = test[\"comment_text\"].fillna(\"CVxTz\").values  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv-d7kV0wuIj"
      },
      "source": [
        "tokenizer = text.Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(list_sentences_train))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
        "X_t = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "X_te = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tYRZJqdwqva"
      },
      "source": [
        "def get_model():\n",
        "    embed_size = 128\n",
        "    inp = Input(shape=(maxlen, ))\n",
        "    x = Embedding(max_features, embed_size)(inp)\n",
        "    x = Bidirectional(LSTM(50, return_sequences=True))(x)\n",
        "    x = GlobalMaxPool1D()(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(50, activation=\"relu\")(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(6, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "\n",
        "file_path=\"weights_base.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K8cNYRzxYSy",
        "outputId": "f26d84f9-8b26-4406-bab7-94862a1b1bc7"
      },
      "source": [
        "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n",
        "callbacks_list = [checkpoint, early] #early\n",
        "model.fit(X_t, y, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=callbacks_list)\n",
        "model.load_weights(file_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4488/4488 [==============================] - 576s 128ms/step - loss: 0.0946 - accuracy: 0.8849 - val_loss: 0.0511 - val_accuracy: 0.9940\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.05113, saving model to weights_base.best.hdf5\n",
            "Epoch 2/2\n",
            "4488/4488 [==============================] - 574s 128ms/step - loss: 0.0462 - accuracy: 0.9913 - val_loss: 0.0484 - val_accuracy: 0.9934\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.05113 to 0.04837, saving model to weights_base.best.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Iik6mcyxu0j"
      },
      "source": [
        "y_test = model.predict(X_te)\n",
        "sample_submission = pd.read_csv(\"/content/drive/MyDrive/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\")\n",
        "sample_submission[list_classes] = y_test\n",
        "sample_submission.to_csv(\"baseline.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBriP4722Ob7"
      },
      "source": [
        "pickle.dump(tokenizer, open('/content/drive/MyDrive/jigsaw-toxic-comment-classification-challenge/tokernizer.pickle', 'wb')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1oEAN1y4Ic3",
        "outputId": "7c346d93-1b2d-4cef-8af0-390394d21c0e"
      },
      "source": [
        "model.save('/content/drive/MyDrive/jigsaw-toxic-comment-classification-challenge/model/') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/jigsaw-toxic-comment-classification-challenge/model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/jigsaw-toxic-comment-classification-challenge/model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mdsoHTI42hX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}